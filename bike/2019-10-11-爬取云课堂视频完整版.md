爬取云课堂视频完整版

```python
#!/usr/bin/env python
# -*- encoding: utf-8 -*-
# 下载云课堂视频
# 视频切片地址 https://slice.ydma.com/course/1950/lesson/7155/994/000000
'''
 开始地址 http://www.ydma.com/classroom/778/task/1379
 视频切片地址  data-key="course/1950/lesson/7155/994"
 切片规则 https://slice.ydma.com/course/1950/lesson/7155/994/000000

'''

from urllib import request
from urllib import error
import re
import os
import requests

class Reptile(object):
    #添加请求头 和 Cookie
    headers = {
        'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.90 Safari/537.36',
        'Cookie': '值'
    }

    def Get_Titles_and_dirname(self,url):
        html = requests.get(url, headers=self.headers)
        #获取顶级标题  用标题名字建立文件夹
        #标题获取正则
        title_regular = '<title>.*-(.*)-.*</title>'
        #获取标题
        title_res = re.search(title_regular,html.text)
        title_str = title_res.group(1).strip()
        print('获取到一级标题:',title_str)
        if os.path.isdir(title_str) == False:
            print('建立目录')
            os.makedirs(title_str)
        else:
            pass
        self.Make_Two_Titles_and_dirname(url,title_str)
        


    def Make_Two_Titles_and_dirname(self,url,dirname):
        html = requests.get(url, headers=self.headers)
        print('---------------------------开始获取课程---------------------------')
        twodir_regular = 'showLessions\(.*\d\)\">(.*)</a>'
        twodir_str = re.findall(twodir_regular,html.text)
        #获取二级目录链接
        link_regular = 'data-lesson-url="(.*)">'
        link_url = re.findall(link_regular,html.text)
        print('开始获取二级课程标题')
        for key,value in zip(twodir_str,link_url):
            #打印二级目录课程标题 和链接
            print(key,value)
            if os.path.isdir(os.path.join(dirname,key)) == False:
                print('开始建立课程目录：',os.path.join(dirname,key))
                os.makedirs(os.path.join(dirname,key.strip()))
                print()
            else:
                pass
            url = value
            dirnames = os.path.join(dirname,key).strip()
            self.Get_title_Three_and_dirname(url,dirnames)
            

    def Get_title_Three_and_dirname(self,url,dirnames):

        #获取视频课时标题
        html = requests.get(url,headers = self.headers)
        video_regular= 'title">(.*)</span>'
        # 注意 去掉 第一个列表
        video_str= re.findall(video_regular,html.text)
        del video_str[0]

        #获取视频url
        video_url_regular = ' href="(.*)"'
        video_url= re.findall(video_url_regular,html.text)

        for key,value in zip(video_str,video_url):
            #print(key,value)
            if os.path.isdir(os.path.join(dirnames,key)) == False:
                print(os.path.join(dirnames,key.strip()))
                os.makedirs(os.path.join(dirnames,key.strip()))
            url = value
            dernamed = os.path.join(dirnames,key.strip())
            self.Get_url(url,dernamed)

    def Get_url(self,url,dernamed):
        html = requests.get(url,headers = self.headers)
        Get_url_regular = 'data-key="(.*)"'
        Get_url_str= re.search(Get_url_regular,html.text)
        urls = (Get_url_str.group(1))
        url_str = 'https://slice.ydma.com/'+ urls
        url = url_str
        self.down(url,dernamed)


    def down(self,url,dirnamed):

        uid = [str(i).zfill(6) for i in range(0, 1000)]
        for i in uid:
            urls = os.path.join(url,i)
            dirname = os.path.join(dirnamed,i)
            try:
                response = request.urlopen(urls)
                print(urls, response.status)
            except error.HTTPError as e:
                if e.code == 404:
                    print('当前视频下载完成,开始下载一下视频！')
                    return True

            else:
                print('开始下载',dirnamed)
                f = request.urlopen(urls)
                data = f.read()
                with open(dirname, 'wb') as code:
                    code.write(data)
                    code.close()









scan = Reptile()
url = 'http://www.ydma.com/classroom/778/task/1381'
scan.Get_Titles_and_dirname(url)





```